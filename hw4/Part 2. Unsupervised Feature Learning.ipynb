{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Unsupervised feature learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem you will see how unsupervised learning can help you train better models even with labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x = 32 # width of image\n",
    "image_y = 32 # height of image\n",
    "patch_dim = 8 # height/width of a patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image(object):\n",
    "\n",
    "    def __init__(self,data,label,patches):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        -----------\n",
    "        Takes image related data, called on image creation.\n",
    "        \"\"\"\n",
    "        self.label = label # image label\n",
    "        self.patches = patches.transpose().tolist()\n",
    "        \n",
    "        self.__img_data = data\n",
    "\n",
    "    def view(self):\n",
    "        \"\"\"\n",
    "        Function: View\n",
    "        --------------\n",
    "        Call function to view RGB image\n",
    "        \"\"\"\n",
    "        from PIL import Image\n",
    "        im = Image.fromarray(self.__img_data)\n",
    "        im = im.resize((128,128),Image.BILINEAR)\n",
    "        plt.imshow(im)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    def get_label(self):\n",
    "        \"\"\"\n",
    "        Function: Label\n",
    "        ---------------\n",
    "        Returns label of image\n",
    "        \"\"\"\n",
    "        return self.label\n",
    "\n",
    "    def get_patches(self):\n",
    "        \"\"\"\n",
    "        Function: Patches\n",
    "        -----------------\n",
    "        Returns list of patch vectors. Each patch length patch_size\n",
    "        \"\"\"\n",
    "        return self.patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_helper(name,m):\n",
    "    channels = 3\n",
    "    patch_dim = 8\n",
    "    patches_per_image = (image_x/patch_dim)*(image_y/patch_dim)\n",
    "\n",
    "    images = np.fromfile('data/CIFAR/images_'+name+'.bin',dtype=np.uint8)\n",
    "    images = images.reshape((m,image_x,image_y,channels))\n",
    "\n",
    "    patches = np.fromfile('data/CIFAR/patches_'+name+'.bin',dtype=np.float32)\n",
    "    patches = patches.reshape((patch_dim**2,-1))\n",
    "\n",
    "    labels = np.fromfile('data/CIFAR/labels_'+name+'.bin',dtype=np.uint8)\n",
    "\n",
    "    image_list = []\n",
    "    for i in range(images.shape[0]):\n",
    "        image_list.append(Image(images[i,...],labels[i],\n",
    "          patches[:,int(i*patches_per_image):int((i+1)*patches_per_image)]))\n",
    "    \n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_helper(patches,num):\n",
    "    from PIL import Image\n",
    "    \n",
    "    xnum = int(np.sqrt(num))\n",
    "    if xnum**2 == num:\n",
    "        ynum = xnum\n",
    "    else:\n",
    "        ynum = xnum+1\n",
    "\n",
    "    imDim = 50\n",
    "\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        patches = patches-np.min(patches)\n",
    "        patches = patches/np.max(patches)\n",
    "        patchDim = patches.shape[0]\n",
    "        image = np.zeros(((patchDim+1)*ynum+1,(patchDim+1)*xnum+1))\n",
    "        for i in range(ynum):\n",
    "            for j in range(xnum):\n",
    "                imnum = i*xnum+j\n",
    "                if imnum>=num:\n",
    "                    break\n",
    "                ax = plt.subplot2grid((ynum,xnum),(i,j))\n",
    "                if i < 3:\n",
    "                    print(i, \": \", xnum, \": \", j)\n",
    "                ax.imshow(patches[:,:,i*xnum+j].squeeze(), cmap = plt.get_cmap('gray'))\n",
    "                ax.axes.get_xaxis().set_visible(False)\n",
    "                ax.axes.get_yaxis().set_visible(False)\n",
    "                \n",
    "        plt.subplots_adjust(wspace=-.5 ,hspace=0.2)\n",
    "        plt.show()\n",
    "        return\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # rescale to be [0-255]\n",
    "    patches = patches-np.min(patches)\n",
    "    patches = 255*patches/np.max(patches)\n",
    "\n",
    "    newpatches = np.empty((imDim,imDim,num))\n",
    "\n",
    "    for p in range(num):\n",
    "        patch = patches[:,:,p].squeeze().copy()\n",
    "        im = Image.fromarray(patch)\n",
    "        im = im.resize((imDim,imDim),Image.BILINEAR)\n",
    "        newpatches[:,:,p] = np.asarray(im.convert('L'))\n",
    "\n",
    "    patches = newpatches\n",
    "    image = np.zeros(((imDim+1)*ynum+1,(imDim+1)*xnum+1))\n",
    "\n",
    "    for i in range(ynum):\n",
    "        for j in range(xnum):\n",
    "            imnum = i*xnum+j\n",
    "            if imnum>=num:\n",
    "                break\n",
    "            image[i*(imDim+1)+1:i*(imDim+1)+imDim+1, \\\n",
    "                  j*(imDim+1)+1:j*(imDim+1)+imDim+1] \\\n",
    "                  = patches[:,:,imnum]\n",
    "    image = Image.fromarray(image, 'L')\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_features(images):\n",
    "    \"\"\"\n",
    "    Extracts raw pixel features for all images.  Returns a 2-D array\n",
    "    of size featDim x numExamples and a vector of labels.\n",
    "    \"\"\"\n",
    "    X = [np.array(image.get_patches()).ravel() for image in images]\n",
    "    X = np.vstack(X).transpose() # featdim by num samples\n",
    "    # label array\n",
    "    Y = np.array([image.get_label() for image in images])\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_patches(patches):\n",
    "    \"\"\"\n",
    "    Function: View Patches\n",
    "    ----------------------\n",
    "    Pass in an array of patches (or centroids) in order to view them as\n",
    "    images.\n",
    "    \"\"\"\n",
    "    view_helper(patches.reshape(patch_dim,patch_dim,-1),patches.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_images = 2000\n",
    "file_tag = 'train'\n",
    "train_image_list = load_helper(file_tag,num_train_images)\n",
    "\n",
    "num_test_images = 1000\n",
    "file_tag = 'test'\n",
    "test_image_list = load_helper(file_tag,num_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,train_Y = pixel_features(train_image_list)\n",
    "test_X,test_Y = pixel_features(test_image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 2000), (2000,), (1024, 1000), (1000,))"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_Y.shape, test_X.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 1000), (1000,))"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_X[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train logistic regression on the raw pixel data and report the train and test set results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = preprocessing.scale(train_X)\n",
    "logreg = LogisticRegression(max_iter=1000).fit(train_X.T, train_Y)\n",
    "\n",
    "test_X = preprocessing.scale(test_X)\n",
    "pred_X = logreg.predict(test_X.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression =  0.535\n"
     ]
    }
   ],
   "source": [
    "log_acc = accuracy_score(test_Y, pred_X)\n",
    "print(\"Accuracy of the Logistic Regression = \", log_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train SVM on the raw pixel data and report the train and test set results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Support Vector Machine Classifier =  0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sofiapetryshyn/opt/anaconda3/envs/mypython3/lib/python3.6/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "st_sc = StandardScaler()\n",
    "st_sc.fit_transform(train_X)\n",
    "suppvm = svm.SVC(max_iter=50).fit(train_X.T, train_Y)\n",
    "pred_X = suppvm.predict(test_X.T)\n",
    "svm_acc = accuracy_score(test_Y, pred_X)\n",
    "\n",
    "print(\"Accuracy of the Support Vector Machine Classifier = \", svm_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train XGBoost on the raw pixel data and report the train and test set results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(train_X.T, label=train_Y)\n",
    "dtest = xgb.DMatrix(test_X.T, label=test_Y)\n",
    "\n",
    "# xgb_classifier = XGBClassifier()\n",
    "\n",
    "param = {\n",
    "    'max_depth': 4,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 2\n",
    "}\n",
    "epochs = 10\n",
    "\n",
    "model = xgb.train(param, dtrain, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the XGBoost =  0.651\n"
     ]
    }
   ],
   "source": [
    "xgb_acc = accuracy_score(test_Y, pred_X)\n",
    "\n",
    "print(\"Accuracy of the XGBoost = \", xgb_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning better features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of hand-designing better features let us see if we can learn them directly from data. Each image is a 32x32 grid of pixels. We will divide the image into sixteen 8x8 \"patches\". Next, we will use K-means to cluster all the patches into centroids. These centroids will then allow us to use a better feature representation of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how we can get patches from the images and visualize them. Make sure you understand the dimensions of every array and what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 2000\n",
    "patches = np.hstack([np.array(image.get_patches()).transpose() for image in train_image_list[:num_images]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One patch is 8 horizontal values and 8 vertical values inlined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 64)"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 46 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "patch_size = (8, 8)\n",
    "\n",
    "# visualize a random set of patches\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ctr = 0\n",
    "for i in range(0, len(patches), 700):\n",
    "    ax=fig.add_subplot(10, 10, ctr + 1)    \n",
    "    ax.axis('off')\n",
    "    ax.imshow(patches[i].reshape(patch_size), cmap='gray')\n",
    "    ctr+=1\n",
    "    if ctr >= len(patches):\n",
    "        break\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=10, n_init=3)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k_means_pca = KMeans(n_clusters=10, n_init=3, max_iter=300)\n",
    "k_means_pca.fit(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = k_means_pca.cluster_centers_ # Please use this variable name for the array of centroids\n",
    "# the limit is i < 3, not to have a lot of data printed\n",
    "# view_patches(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing examples in a new way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you have the centroids defining similar groups in your patches. Represent every image in your training and test set in distances between the patch and each centroid. For example, if you used 10 clusters and each image has 16 patches, new representation of the image will be a vector of 160 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 7, 2, ..., 6, 3, 0], dtype=int32)"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_kmeans = k_means_pca.predict(patches)\n",
    "pred_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_kmeans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patches[0:16] - one image\n",
    "# from scipy.spatial.distance import cdist\n",
    "\n",
    "all_imgs = []\n",
    "old, num_img = 0, 0\n",
    "for new in range(16, len(patches) + 1, 16):\n",
    "    img_distances = []\n",
    "    img = patches[old:new]\n",
    "    for patch in img:\n",
    "        for claster in range(0, 10):\n",
    "            centroid_patch = centroids[claster]\n",
    "            patches_dist = np.linalg.norm(patch - centroid_patch)\n",
    "            img_distances.append(patches_dist)\n",
    "    all_imgs.append(np.asarray(img_distances))\n",
    "    old += 16\n",
    "    \n",
    "all_imgs = np.asarray(all_imgs)\n",
    "#     print(all_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.21419704, 11.92722027, 12.13928219, ...,  8.40404954,\n",
       "         8.76223975,  8.34372569],\n",
       "       [ 3.99916358,  4.42354106,  4.99836123, ...,  7.02295472,\n",
       "         5.25054544,  6.66201204],\n",
       "       [ 7.54189025,  7.22693811,  7.09985326, ...,  7.74094477,\n",
       "         7.55859944,  7.0047128 ],\n",
       "       ...,\n",
       "       [ 5.94047073,  5.84646049,  5.94265366, ..., 12.23520422,\n",
       "        12.24760276, 11.99467842],\n",
       "       [ 7.34689785,  7.0710942 ,  7.40462829, ...,  8.32574922,\n",
       "         8.39610636,  7.94458284],\n",
       "       [ 2.25600639,  1.76883209,  1.85880887, ...,  5.70596249,\n",
       "         5.57099078,  4.87042639]])"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(all_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 1000\n",
    "patches_test = np.hstack([np.array(image.get_patches()).transpose() for image in test_image_list[:num_images]]).T\n",
    "\n",
    "all_test_imgs = []\n",
    "old, num_img = 0, 0\n",
    "for new in range(16, len(patches_test) + 1, 16):\n",
    "    img_distances = []\n",
    "    img = patches[old:new]\n",
    "    for patch in img:\n",
    "        for claster in range(0, 10):\n",
    "            centroid_patch = centroids[claster]\n",
    "            patches_dist = np.linalg.norm(patch - centroid_patch)\n",
    "            img_distances.append(patches_dist)\n",
    "    all_test_imgs.append(np.asarray(img_distances))\n",
    "    old += 16\n",
    "    \n",
    "all_test_imgs = np.asarray(all_test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 160), (2000, 160))"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_imgs.shape, all_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000,), (2000,))"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y.shape, train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train all three classifiers from the above (logistic regression, SVM and XGBoost) on the new image representation. Report the train and test set results.\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs = preprocessing.scale(all_imgs)\n",
    "logreg_dist = LogisticRegression(max_iter=1000).fit(all_imgs, train_Y)\n",
    "\n",
    "all_test_imgs = preprocessing.scale(all_test_imgs)\n",
    "pred_X_dist = logreg_dist.predict(all_test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression on Compressed Data =  0.518\n"
     ]
    }
   ],
   "source": [
    "log_acc_dist = accuracy_score(test_Y, pred_X_dist)\n",
    "print(\"Accuracy of the Logistic Regression on Compressed Data = \", log_acc_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sofiapetryshyn/opt/anaconda3/envs/mypython3/lib/python3.6/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Support Vector Machine Classifier on Compressed Data =  0.514\n"
     ]
    }
   ],
   "source": [
    "st_sc.fit_transform(all_imgs)\n",
    "suppvm_d = svm.SVC(max_iter=1000).fit(all_imgs, train_Y)\n",
    "pred_X = suppvm_d.predict(all_test_imgs)\n",
    "svm_acc_d = accuracy_score(test_Y, pred_X)\n",
    "\n",
    "print(\"Accuracy of the Support Vector Machine Classifier on Compressed Data = \", svm_acc_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the XGBoost =  0.651\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X.T, label=train_Y)\n",
    "dtest = xgb.DMatrix(test_X.T, label=test_Y)\n",
    "\n",
    "# xgb_classifier = XGBClassifier()\n",
    "\n",
    "param = {\n",
    "    'max_depth': 4,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 2\n",
    "}\n",
    "epochs = 10\n",
    "\n",
    "model = xgb.train(param, dtrain, epochs)\n",
    "\n",
    "pred_X = model.predict(dtest)\n",
    "\n",
    "xgb_acc_d = accuracy_score(test_Y, pred_X)\n",
    "\n",
    "print(\"Accuracy of the XGBoost on Compressed Data = \", xgb_acc_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  0.535 \t\t\t SVM:  0.55 \t\t\t XGBoost 0.625\n",
      "****************************************************************************************************\n",
      "Logistic Regression:  0.518 \t\t\t SVM:  0.514 \t\t\t XGBoost 0.651\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression: \", log_acc,\"\\t\\t\\t SVM: \",  svm_acc, \"\\t\\t\\t XGBoost\", xgb_acc)\n",
    "print(\"*\"* 100)\n",
    "print(\"Logistic Regression: \", log_acc_dist,\"\\t\\t\\t SVM: \",  svm_acc_d, \"\\t\\t\\t XGBoost\", xgb_acc_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the best out of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In industry, we typically try to get as much as possible out of the data we have. Try different number of clusters and different configuration of the models and report the best accuracy you got on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Conclussion:\n",
    "Definitely, the best model is XGBoost, that is because we use gradient boosted trees algorithm, we can set particular paramethers to evaluate model better. When Logistic Regression and SVM are simplier classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
